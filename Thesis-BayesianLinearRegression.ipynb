{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Gen\n",
    "using Flux\n",
    "using JLD\n",
    "using Random\n",
    "using StatsBase\n",
    "using LinearAlgebra\n",
    "using PyPlot\n",
    "using Distributions\n",
    "\n",
    "include(\"LoadData.jl\")\n",
    "include(\"NUTS.jl\")\n",
    "include(\"utils.jl\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Boston Housing Data\n",
    "dx, dy, x_train, x_test, y_train, y_test = load_data(3);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bayesian Linear Regression\n",
    "\n",
    "function G(x,trace)\n",
    "    \n",
    "    Wₒ = reshape(trace[:W], 1, 13)\n",
    "    bₒ = trace[:b]\n",
    "    \n",
    "    nn_out = Dense(Wₒ, bₒ)\n",
    "    return nn_out(x)\n",
    "    \n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Probabilistic Model\n",
    "\n",
    "@gen function interpolator(x)\n",
    "    \n",
    "    #Create a blank choicemap\n",
    "    obs = choicemap()::ChoiceMap\n",
    "    \n",
    "    #Standard Deviations\n",
    "    #τᵧ ~ gamma(100,0.2) #(100,0.5)\n",
    "    τᵧ ~ gamma(1,1)\n",
    "    σᵧ = 1/(τᵧ)\n",
    "    \n",
    "    #Sample weight and bias vectors\n",
    "    u = zeros(13)\n",
    "    S = Diagonal([1 for i=1:length(u)])\n",
    "    W = @trace(mvnormal(u,S), :W)\n",
    "    ub = zeros(1)\n",
    "    Sb = Diagonal([1 for i=1:length(ub)])\n",
    "    b = @trace(mvnormal(ub,Sb), :b)\n",
    "\n",
    "    obs[:W] = W\n",
    "    obs[:b] = b\n",
    "    \n",
    "    #Return Network Scores for X\n",
    "    scores = transpose(G(x,obs))[:,1]\n",
    "    #println(scores)\n",
    "    \n",
    "    #Regression Likelihood\n",
    "    y = @trace(mvnormal(vec(scores), Diagonal([σᵧ for i=1:length(x[1,:])])), (:y))\n",
    "\n",
    "    return scores\n",
    "    \n",
    "end\n",
    "\n",
    "obs_master = choicemap()::ChoiceMap\n",
    "obs_master[:y] = y_train\n",
    "obs = obs_master;\n",
    "(trace,) = generate(interpolator, (x_train,), obs)\n",
    "\n",
    "\n",
    "#----------------\n",
    "#Test Likelihood\n",
    "#----------------\n",
    "best_trace, scores, mses = likelihood_regression(x_train, y_train, 1000)\n",
    "PyPlot.scatter(mses, scores)\n",
    "plt.title(\"Comparing Classifier Accuracy to Log Likelihood\")\n",
    "plt.xlabel(\"Classifier MSE\")\n",
    "plt.ylabel(\"Log Likelihood\")\n",
    "\n",
    "pred_y = transpose(G(x_train,best_trace))[:,1]\n",
    "best_mse = mse_scaled(pred_y, y_train)\n",
    "variance = 1/(best_trace[:τᵧ])\n",
    "println(\"Best noise variance: $variance\")\n",
    "println(\"Best MSE: $best_mse\")\n",
    "println(\"Best Score: $(get_score(best_trace))\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Straight NUTS\n",
    "Δ_max = 1000\n",
    "obs_master = choicemap()::ChoiceMap\n",
    "obs_master[:y] = y_train\n",
    "obs = obs_master;\n",
    "(trace,) = generate(interpolator, (x_train,), obs)\n",
    "#trace = best_trace\n",
    "sigma = 1/(trace[:τᵧ]) #Best so far: 3.0483\n",
    "println(\"$sigma\")\n",
    "\n",
    "#Trace 1\n",
    "param_selection = select()\n",
    "\n",
    "for i=1:1 #Number of Layers\n",
    "    push!(param_selection, :W)\n",
    "    push!(param_selection, :b)\n",
    "end\n",
    "\n",
    "m=100\n",
    "\n",
    "traces = NUTS(trace, param_selection, 0.65, m+1, m, true); #m+1, m=100, 0.65\n",
    "accs = []\n",
    "\n",
    "#-----------------------------------\n",
    "#Plot Log Posterior Scores by Trace\n",
    "#-----------------------------------\n",
    "\n",
    "plot([get_score(trace) for trace in traces])\n",
    "plt.title(\"NUTS Score: Boston Housing Price\")\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Log Posterior\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------------------\n",
    "#Plot RMSE Train Scores by Trace\n",
    "#-------------------------------\n",
    "\n",
    "mses_train = []\n",
    "for i=1:length(traces)\n",
    "    trace = traces[i]\n",
    "    pred_y = transpose(G(x_train,trace))[:,1]\n",
    "    mse = mse_scaled(pred_y,y_train)\n",
    "\n",
    "    push!(mses_train,mse)\n",
    "end\n",
    "\n",
    "mses_test = []\n",
    "for i=1:length(traces)\n",
    "    trace = traces[i]\n",
    "    pred_y = transpose(G(x_test,trace))[:,1]\n",
    "    mse = mse_scaled(pred_y,y_test)\n",
    "\n",
    "    push!(mses_test,mse)\n",
    "end\n",
    "\n",
    "plot(mses_train,label=\"Train\")\n",
    "plot(mses_test, label=\"Test\")\n",
    "plt.title(\"NUTS RMSE: Boston Housing Price\")\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"RMSE\");\n",
    "plt.legend()\n",
    "\n",
    "best_trace = traces[1]\n",
    "for i=1:length(traces)\n",
    "    if get_score(traces[i]) > get_score(best_trace)\n",
    "        best_trace = traces[i]\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------\n",
    "#Marginalize RMSE\n",
    "#----------------\n",
    "j = 20\n",
    "y_marginal = zeros(length(y_train))\n",
    "\n",
    "for i=j:length(traces)\n",
    "    trace = traces[i]\n",
    "    pred_y = transpose(G(x_train,trace))[:,1]\n",
    "    y_marginal += (pred_y/(length(traces)-j))\n",
    "end\n",
    "\n",
    "#display(y_marginal[1:5])\n",
    "#display(y[1:5])\n",
    "\n",
    "mse = mse_scaled(y_marginal, y_train)\n",
    "println(\"Training Set Marginal RMSE: $mse\")\n",
    "\n",
    "j = 20\n",
    "y_marginal = zeros(length(y_test))\n",
    "\n",
    "for i=j:length(traces)\n",
    "    trace = traces[i]\n",
    "    pred_y = transpose(G(x_test,trace))[:,1]\n",
    "    y_marginal += (pred_y/(length(traces)-j))\n",
    "end\n",
    "\n",
    "#display(y_marginal[1:5])\n",
    "#display(y[1:5])\n",
    "\n",
    "mse = mse_scaled(y_marginal, y_test)\n",
    "println(\"Test Set Marginal RMSE: $mse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NUTS with Hyperparam Sampling\n",
    "\n",
    "traces = []\n",
    "for i=1:100\n",
    "    prev_trace = trace\n",
    "    trace = NUTS(trace, param_selection, 0.25, m+1, m, false)[m+1];\n",
    "       \n",
    "    hyper_selection = select()\n",
    "    push!(hyper_selection, :τᵧ)\n",
    "    (trace, _, _) = regenerate(trace, hyper_selection)\n",
    "    \n",
    "    u = rand(Uniform(0,1))\n",
    "    score = get_score(trace) - get_score(prev_trace)\n",
    "    if log(u) < score\n",
    "        trace = trace\n",
    "        if score == 0\n",
    "            push!(accs,0)\n",
    "        else\n",
    "            push!(accs,1)\n",
    "        end\n",
    "    else\n",
    "        trace = prev_trace\n",
    "        push!(accs,0)\n",
    "    end\n",
    "    push!(traces,trace)\n",
    "    \n",
    "    if i%10 == 0\n",
    "        println(\"Epoch $i Acceptance: $(sum(accs)/length(accs))\")\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bayesian Neural Net (Function)\n",
    "function G(x, \n",
    "        trace, \n",
    "        activation=sigmoid\n",
    "    )\n",
    "    \n",
    "    d = length(x[:,1]) #Dimension\n",
    "\n",
    "    l = trace[:l]\n",
    "    ks = [trace[(:k,i)] for i=1:layers]\n",
    "    \n",
    "    for i=1:l\n",
    "        in_dim, out_dim = layer_unpacker(i, l, ks, d)\n",
    "        W = reshape(trace[(:W,i)], out_dim, in_dim)\n",
    "        b = reshape(trace[(:b,i)], trace[(:k,i)])\n",
    "        nn = Dense(W, b, activation)\n",
    "        x = nn(x)\n",
    "    end\n",
    "    \n",
    "    Wₒ = reshape(trace[(:W,l+1)], 1, ks[l])\n",
    "    bₒ = reshape(trace[(:b,l+1)], 1)\n",
    "    \n",
    "    nn_out = Dense(Wₒ, bₒ)\n",
    "    return nn_out(x)\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run Inference"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.4.2",
   "language": "julia",
   "name": "julia-1.4"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.4.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
